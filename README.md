# Competitions
Competitions is an open source tool to run NIH-style peer review of competitions, pilot projects, and research proposals in a cloud-based consortium-wide single sign-on platform.

## Problem statement
A platform to support robust peer review within and across CTSA hubs does not currently exist. Competitions is a software tool for investigators, reviewers and administrators to run various types of reviews and competitions, including pilot projects, research awards and reviews. 

## Project description
Here, we will upgrade Competitions platform (1) to support CTSA consortium-wide peer-review activities through a cloud-deployment that supports single sign-on and (2) enhance the competitions code base to improve the ease and robustness of local adoption by interested institutions.


## Alignment to program objectives
See the Funding Opportunity Announcement (FOA) [here](https://github.com/data2health/roadmap/blob/master/cd2h-foa.md).


## Contact person

We require a contact person for each project for administrative purposes. Each project should also have a CD2H Program director assigned.

Point person (github handle) | Site | Program Director
----------|--------------|---------------
Laura Wimbiscus (@lmkw) | Northwestern | 

## Leads  

Lead(s) (github handle) | Site
----------|--------------|
Matthew Baumann (@mattbaumann1) | Northwestern 
John Serafin (@jseraf) | Northwestern
Firas Wehbe (@firaswehbe) | Northwestern


## Team members 

See https://github.com/data2health/competitions-project/tree/master/team.md

## Repositories

- CD2H Phase II project repo: https://github.com/data2health/competitions-project
- Code repo: https://github.com/NUARIG/competitions

## Deliverables
A functioning prototype of a CTSA Program-level competition review tool for projects and events that can be used in the cloud or implemented locally, if desired


## Milestones 
- Set up authentication
- Set up cloud or local hosting environment
- Code Competitions for cloud
- User acceptance testing
- Evaluation work stream

## Evaluation
- Usage metrics of the cloud instance: unique user counts, unique user log-ins, active competitions created, number of submissions, reviews, etc.
- Local adoption (attempted, successful)
- Measure of open-source contribution: Pull requests, GitHub issues (opened, resolution, and unique contributors)


## Education
*Each project should propose a set of educational activities, listed separately in the Education Plan file.*
*Please reference any of the following that apply:*
*- Educational resources that will be generated (these can be milestones and/or files in the repo)*
*- Educational opportunities (please indicate for which type of learner and how to participate)*
*- Best practices guides*

*Please include education related issues where relevant, tagged with "education".*

## Get involved (Engagement)
Technical:
- Pilot the platform, provide feedback (features, documentation, implementation workflows, etc), contribute to development via open source workflow e.g. GitHub fork and pull request, contribute to documentation, submit feature requests, participate in SAML  infrastructure to enable SSO (applies to all cloud-based deployments not just Competitions)

Cultural:
- Develop use cases, be a demonstration partner, provide feedback on product design, utilize the cloud-deployed instance, develop local implementation strategies, test local engagement materials, seek requirements, share strategies to support local projects; collaborate on best practices for local adoption, implementation, engagement, integration


## Working documents
*As this project progresses, working documents will be made available either through this project's wiki or via other means like Google Drive folders*

## Slack room
*[The project slack room](https://cd2h.slack.com/messages/CG7EQ74UB/) is accessible to onboarded participants. You will not automatically be added to Slack, please join via the link above.*

